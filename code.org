#+TITLE: Greenland Ice Sheet borehole temperature profiles
#+AUTHOR: Ken Mankoff
#+EMAIL: kdm@geus.dk
#+DATE: {{{time(%Y-%m-%d)}}}
#+DESCRIPTION:
#+KEYWORDS:
#+OPTIONS:   H:4 num:4 toc:2 \n:nil ::t |:t ^:{} -:t f:t *:t <:t
#+EXCLUDE_TAGS: noexport
#+ARCHIVE: ::* Archive

#+PROPERTY: header-args:jupyter-python+ :session boreholes :kernel ds
#+PROPERTY: header-args:python :python "/home/kdm/local/miniconda3/envs/ds/bin/jupyter-console"

# Note, when exporting LaTeX also: =biber README --output_format bibtex -O library.bib=
  
* ODS from Google Sheet

+ We use the Google Sheet spreadsheet to generate a local [[./meta.csv]]
+ https://docs.google.com/spreadsheets/d/1QNqnjO7Gocl29Y7X693rCRRZI4dTSq0i58YghWeHy2Q/edit#gid=765194309

#+NAME: sheet2csv
#+BEGIN_SRC jupyter-python
import pandas as pd
import numpy as np

url =  "https://docs.google.com/spreadsheets/d/1QNqnjO7Gocl29Y7X693rCRRZI4dTSq0i58YghWeHy2Q/export?format=csv&gid=765194309"

df = pd.read_csv(url)\
       .set_index('Borehole ID')\
       .drop(columns=['Needs?','High Strain','SMB Regime','Basal State','Measured from: Top, Bottom, Relative'])\
       .replace('\#DIV/0!', np.nan)\
       .replace('\#VALUE!', np.nan)

df['Velocity [m/yr]'] = df['Velocity [m/yr]'].round(1)

# df.to_excel('database.ods')
df.to_csv('meta.csv')
print(df.index)
#+END_SRC

#+RESULTS: sheet2csv
#+begin_example
Index(['Agassiz77', 'Agassiz79a', 'Agassiz79b', 'Agassiz84', 'CampCentury', 'CampIII_78',
       'CampVI_50', 'Devon72', 'Devon73', 'Devon98', 'DYE-3', 'FladeIsblink06', 'FOXX1', 'FOXX2',
       'GISP2', 'GRIP', 'GULL', 'HansTausen_Dome', 'HansTausen_Hare', 'Isua_10', 'Isua_11',
       'Isua_12', 'Isua_13', 'Isua_14', 'Isunnguata_13km-10', 'Isunnguata_27km-11A',
       'Isunnguata_27km-11B', 'Isunnguata_27km-11C', 'Isunnguata_27km-12A', 'Isunnguata_27km-12B',
       'Isunnguata_27km-12C', 'Isunnguata_33km_14N', 'Isunnguata_33km_14SA',
       'Isunnguata_33km_14SB', 'Isunnguata_33km_14W', 'Isunnguata_33km_15CA',
       'Isunnguata_33km_15CB', 'Isunnguata_33km_15E', 'Isunnguata_33km_15N', 'Isunnguata_33km_15S',
       'Isunnguata_46km-11A', 'Isunnguata_46km-11B', 'Isunnguata_M1-10', 'Isunnguata_M2-10B',
       'Jakobshavn89A', 'Jakobshavn89B', 'Jakobshavn89C', 'Jakobshavn95D_I1', 'Jakobshavn95D_I2',
       'Jakobshavn95D_T3', 'Jakobshavn95D_T4', 'Jakobshavn95D_T5', 'Meighen67', 'NEEM', 'NGRIP',
       'Penny96', 'PrinceWales05', 'Renland88', 'SiteII', 'StationCentrale', 'Store_R30_BH19c',
       'Store_S30', 'TD1_88', 'TD2_88', 'TD3_88', 'TD4_91a', 'TD4_91b', 'TD5_90', 'TD5_91',
       'Tuto_D-11'],
      dtype='object', name='Borehole ID')
#+end_example

* meta.bsv from database

#+NAME: csv2metabsv
#+BEGIN_SRC jupyter-python
import pandas as pd
import numpy as np

df = pd.read_csv('meta.csv', index_col=0)

for r in df.index:
    row = df.loc[r]
    row.index.name = 'Borehole ID'
    # row = row.drop(['Measured from: Top, Bottom, Relative'])
    try:
        row.to_csv(row.name + '/meta.bsv', sep='|')
    except:
        pass
#+END_SRC

#+RESULTS: csv2metabsv

* Location KML

#+NAME: kml
#+BEGIN_SRC jupyter-python
import pandas as pd
import simplekml
import cgi

df = pd.read_csv('meta.csv', index_col=0)

kml = simplekml.Kml()
for site in df.index:
    coords=df.loc[site]['Longitude [°E]'], df.loc[site]['Latitude [°N]']
    if np.all(np.isfinite(coords)):
        p = kml.newpoint(name=site, coords=[coords])
        for n in df.loc[site].index:
            p.extendeddata.newdata(n, cgi.html.escape(str(df.loc[site, n])))
                                    
kml.save("boreholes.kml")
#+END_SRC

#+RESULTS: kml

* Build temperature.csv

+ Combine each =<site>/data.csv= into a single [[./temperature.csv]] CSV file for all sites

#+NAME: meta2temperatureCSV    
#+BEGIN_SRC jupyter-python
import os
import glob
import pandas as pd

index = np.arange(4E3)
df = pd.DataFrame(index=index)
df.index.name = 'd'

db = pd.read_csv('meta.csv', header=[0])
# db.columns:
# Index(['Borehole ID', 'Place name', 'Geographic location', 'Ice type', 'Data Source', 'Data DOI',
#        'Science Source', 'Science DOI', 'Date', 'Longitude [°E]', 'Latitude [°N]',
#        'Location Source', 'Depth of top measurement [m]', 'Depth of bottom measurement [m]',
#        'Ice thickness [m]', 'Coverage [% of thickness]', 'Ice thickness source',
#        'Measured from: Top, Bottom, Relative', 'General note', 'Thickness note', 'Location note'],
#       dtype='object')

db = db[~(db['Borehole ID'] == 'Jakobshavn89C')]
 
columns = pd.MultiIndex.from_arrays([db['Borehole ID'],
                                     db['Date'],
                                     db['Longitude [°E]'],
                                     db['Latitude [°N]'],
                                     db['Velocity [m/yr]'],
                                     db['Depth of top measurement [m]'],
                                     db['Depth of bottom measurement [m]'],
                                     db['Ice thickness [m]']],
                                    names=['Borehole ID',
                                           'Date',
                                           'Longitude [°E]',
                                           'Latitude [°N]',
                                           'Velocity [m/yr]',
                                           'Depth of top measurement [m]',
                                           'Depth of bottom measurement [m]',
                                           'Ice thickness [m]'])

for id in db['Borehole ID']:
  if id == 'Jakobshavn89C': continue
  
  m = pd.read_csv(id + '/meta.bsv', sep="|", index_col=0).squeeze()

  d = pd.read_csv(id + '/data.csv').set_index('d').rename(columns={'t':m.name})
  d.index = np.round(d.index).astype(int)
  d = d.groupby(d.index).mean()
  df = df.merge(d, left_index=True, right_index=True, how='outer')

df.index.name = "depth [m]"
# interpolate w/ PCHIP no overshoot
df = df.interpolate(limit_area='inside', method='pchip')
df.index = df.index.astype(int)

df = df[df.index > 0]

# set below bedrock to -999
for id in db['Borehole ID']:
  thick = db[db['Borehole ID'] == id]['Ice thickness [m]'].values[0]
  try: 
    thick = int(thick)
  except:
    continue
  df[id][thick:] = -999

maxdepth = df.replace(-999,np.nan).dropna(how='all').index.max()
df = df[df.index <= maxdepth]
df.to_csv("temperature.csv", float_format='%.4f')

# add extra header rows
df.columns = columns
df.to_csv("temperature_meta.csv", float_format='%.4f')

print(df[df.columns[0:5]].head(10))
#+END_SRC

#+RESULTS: meta2temperatureCSV
#+begin_example
Borehole ID                     Agassiz77 Agassiz79a Agassiz79b  Agassiz84 CampCentury
Date                                 1977       1979       1979       1984        1966
Longitude [°E]                   -73.1000   -73.1000   -73.1000   -73.1000    -61.1097
Latitude [°N]                     80.7000    80.7000    80.7000    80.7000     77.1797
Velocity [m/yr]                       4.4        4.4        4.4        4.4         7.4
Depth of top measurement [m]         11.0       12.0       11.0       3.0         9.0 
Depth of bottom measurement [m]      341        142        141        128         1387
Ice thickness [m]                     341        142        141        128        1387
depth [m]                                                                             
1                                     NaN        NaN        NaN        NaN         NaN
2                                     NaN        NaN        NaN        NaN         NaN
3                                     NaN        NaN        NaN -23.990000         NaN
4                                     NaN        NaN        NaN -23.581640         NaN
5                                     NaN        NaN        NaN -23.206919         NaN
6                                     NaN        NaN        NaN -22.878379         NaN
7                                     NaN        NaN        NaN -22.608559         NaN
8                                     NaN        NaN        NaN -22.410000         NaN
9                                     NaN        NaN        NaN -22.259543  -24.046765
10                                    NaN        NaN        NaN -22.127927  -24.060787
#+end_example



** Convert temperature.csv to temperature_dnorm.csv

#+BEGIN_SRC jupyter-python
dfN = pd.DataFrame(index=np.linspace(0,100,101).astype(int))
dfN.index.name = 'd normalized'

df = pd.read_csv("temperature_meta.csv", index_col=0, header=[0,1,2,3,4,5,6,7])

# dfN.columns = df.columns

thick = pd.Series(pd.to_numeric(df.columns.get_level_values('Ice thickness [m]'), errors='coerce')).replace(np.nan,0).astype(int).values

id = df.columns.get_level_values('Borehole ID')

for i,c in enumerate(id):
    # if thick[i] == 0:
    #     print(i,c)
    #     continue
    profile = df[c][0:thick[i]]
    # do not round, rather, interpolate to 1 % resolution
    profile['dNorm'] = np.round(profile.index/thick[i]*100).astype(int)
    profile = profile.groupby('dNorm').mean()
    profile.index.name = 'd normalized'
    dfN = dfN.merge(profile, left_index=True, right_index=True, how='outer')

# Add pchip to fill in gaps
dfN.index = dfN.index / 100
dfN.columns = df.columns
dfN.to_csv("temperature_dnorm_meta.csv", float_format='%.4f')

dfN.columns = df.columns.get_level_values(0)
dfN.to_csv("temperature_dnorm.csv", float_format='%.4f')

#+END_SRC

#+RESULTS:
: /home/kdm/local/miniconda3/envs/ds/lib/python3.8/site-packages/pandas/core/reshape/merge.py:643: UserWarning: merging between different levels can give an unintended result (1 levels on the left,7 on the right)
:   warnings.warn(msg, UserWarning)


* Graphics

#+NAME: setup
#+BEGIN_SRC jupyter-python :results none
import matplotlib.pyplot as plt
import matplotlib
from matplotlib import rc
import pandas as pd

rc('font', size=10)
rc('text', usetex=False)
# matplotlib.pyplot.xkcd()

# plt.close(1)
fig = plt.figure(1, figsize=(4*2,5*2)) # w,h
fig.clf()
fig.set_tight_layout(True)
ax = fig.add_subplot(111)
#+END_SRC

** From surface:

#+BEGIN_SRC jupyter-python
<<setup>>

df = pd.read_csv("temperature.csv", index_col=0, header=[0,1,2,3,4,5,6])
df = df.replace(-999, np.nan)
for c in df.columns:
    ax.plot(df[c], -df.index, label=c)
    if size(df[c].dropna()) != 0:
        ax.text(df[c].dropna().values[-1],
                -df[c].dropna().index[-1],
                c[0])

ax.set_xlabel("T [°C]")
ax.set_ylabel("Depth below surface [m]")
plt.savefig('temperature.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:

[[./temperature.png]]


** Normalized

#+BEGIN_SRC jupyter-python
<<setup>>

df = pd.read_csv("temperature_dnorm.csv", index_col=0, header=[0,1,2,3,4,5,6])
df = df.replace(-999, np.nan)
for c in df.columns:
    ax.plot(df[c], df.index, label=c)
    if size(df[c].dropna()) != 0:
        ax.text(df[c].dropna().values[0],
                df[c].dropna().index[0],
                c[0])

ax.set_xlabel("T [°C]")
ax.set_ylabel("Normalized depth below surface [-]")
ax.set_ylim([1,0])
plt.savefig('temperature_dnorm.png', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:

[[./temperature_dnorm.png]]


* Velocity

#+BEGIN_SRC bash
grass -e -c EPSG:3413 G
grass ./G/PERMANENT

v.import input=boreholes.kml output=boreholes

r.in.gdal input="NetCDF:/home/kdm/data/ITS_LIVE/CAN_G0120_0000.nc:v" output=v_can
r.in.gdal input="NetCDF:/home/kdm/data/ITS_LIVE/GRE_G0120_0000.nc:v" output=v_gre

g.region raster=v_can,v_gre -pa
r.patch input=v_can,v_gre output=v

d.mon wx0
d.rast v
d.vect boreholes color=red width=3

v.what.rast map=boreholes type=point raster=v column=v
db.select sql="select Name,v from boreholes" # Check order is correct
db.select sql="select v from boreholes" # Paste into DB
#+END_SRC
